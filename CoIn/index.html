
<html lang="en">

<head>
    <!-- Google Tag Manager -->
    <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-MDPRSPMJ');</script>
    
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <!-- Google tag (gtag.js) -->
    <!--<script async src="https://www.googletagmanager.com/gtag/js?id=G-CEKV88TVGH"></script>
    <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-CEKV88TVGH');
    </script>-->
    
    <title> Adapting Pretrained ViTs with <br>Convolution Injector for Visuo-Motor Control</title>

    <meta name="author" content="Dongyoon Hwang">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <base target="_blank">

    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.4.0/css/font-awesome.min.css">
    <link rel="stylesheet"
    href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="css/bootstrap.min.css">
    <link rel="stylesheet" href="../../stylesheet.css">
    <link rel="stylesheet" href="css/app.css?v=20230203">
    <link rel="icon" type="image/png" sizes="32x32" href="../../images/favicon/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="../../images/favicon/favicon-16x16.png">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.5/js/bootstrap.min.js"></script>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

    <script src="js/app.js"></script>
</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MDPRSPMJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
    <div class="container" id="main">
        <div class="row">
            <h2 class="col-md-12 text-center">
                <b>Adapting Pretrained ViTs with <br>Convolution Injector for Visuo-Motor Control</b>
                 
                <small>
                <br>ICML 2024</small></br>
                </small>
            </h2>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">
                <ul class="list-inline">
                    <li>
                      <a href="https://godnpeter.github.io/">
                      Dongyoon Hwang*
                      </a>
                    </li>
                    <li>
                      Byungkun Lee*
                      </a>
                    </li>
                    <li>
                        <a href="https://joonleesky.github.io/">
                          Hojoon Lee
                        </a>
                    </li>

                    <li>
                      <a href="https://mynsng.github.io/">
                        Hyunseung Kim
                      </a>
                    </li>
                    
                    <li>
                        <a href="https://sites.google.com/site/jaegulchoo/">
                          Jaegul Choo
                        </a>
                    </li>
                    </br>KAIST
                </ul>
            </div>
        </div>


        <style>
            .publication-links .btn {
                border-radius: 50px;
                padding: 10px 20px;
                margin: 5px;
            }
            .publication-links .btn-dark {
                background-color: #363636;
                color: #fff;
            }
            .publication-links .btn-dark:hover {
                background-color: #2d2d2d;
                color: #fff;
            }
            .publication-links .icon {
                margin-right: 5px;
            }
        </style>

        <div class="row">
            <div class="col-md-6 col-md-offset-3 text-center">
                <ul class="list-inline">
                    <li>
                        <a href="https://arxiv.org/abs/2406.06072"><h4><b>[Paper]</b></h4></a>
                    </li>
                    <li>
                        <a href="https://github.com/dojeon-ai/CoIn"><h4><b>[Code]</b></h4></a>
                    </li>
                </ul>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12">
                <h4>
                    <span class="font-weight-normal"><strong style="font-size: 1em;">TL;DR:</strong> Add-on module which injects <b>convolutions</b> into pretrained ViTs for Visuo-motor Control</span>
                </h4>
            </div>
        </div>
        
        <div class="col-md-12">
            <br>
            <div class="col-md-12">
                <p width="50%"  height="auto" style="margin-right:auto;margin-left:auto;text-align:center;">
                    <img src="/CoIn/pictures/performance.png", width="60%">
                </p>
            </div>
        </div>

        <div class="row">
            <div class="col-md-12">
                <h2>
                    <span class="font-weight-normal">Abstract</span>
                </h2>
                <br>
                <p class="text-justify">
                  Vision Transformers (ViT), when paired with large-scale pretraining, have shown remarkable performance across various computer vision tasks, primarily due to their weak inductive bias.
                  However, while such weak inductive bias aids in pretraining scalability, this may hinder the effective adaptation of ViTs for visuo-motor control tasks as a result of the absence of control-centric inductive biases. 
                  Such absent inductive biases include spatial locality and translation equivariance bias which convolutions naturally offer. 
                  To this end, we introduce <b>Convolution Injector (CoIn)</b>, an add-on module that injects convolutions which are rich in locality and equivariance biases into a pretrained ViT for effective adaptation in visuo-motor control. 
                  We evaluate CoIn with three distinct types of pretrained ViTs (CLIP, MVP, VC-1) across 12 varied control tasks within three separate domains (Adroit, MetaWorld, DMC), and demonstrate that CoIn consistently enhances control task performance across all experimented environments and models, validating the effectiveness of providing pretrained ViTs with control-centric biases.
                </p>
            </div>
        </div>

        <hr>
        <div class="row">
            <div class="col-md-6">
                <h2>
                    Motivation
                </h2>
                <br>
                <p>
                    The advent of open-sourced, large-scale ViTs pretrained with extensive web-scale datasets provides generalized, ready-to-go visual representations. 
                    However, their <u>weak inductive bias, though beneficial for scaling, impedes effective visuo-motor control.</u> By integrating convolutional biases for spatial locality and translation equivariance, these limitations can be addressed.
                </p>
            </div>

            <div class="col-md-6">
                <img src="/CoIn/pictures/motivation.png" alt="Overview" class="img-responsive">
            </div>
        </div>
        
        <hr>
        <div class="row">
            <div class="col-md-12">
                <h2>
                    <span class="font-weight-normal">Method: Convolution Injector (CoIn)</span>
                </h2>
                <div class="col-md-12">
                    <br>
                    <div class="col-md-12">
                        <p width="50%"  height="auto" style="margin-right:auto;margin-left:auto;text-align:center;">
                            <img src="/CoIn/pictures/model.png", width="70%">
                        </p>
                    </div>
                </div>
                <br>
                <p class="text-justify">
                    <b>CoIn</b> is a simple and lightweight add-on module (3.6% of additional parameters to a standard ViT-B/16) 
                    designed to exploit the strengths of pretrained ViTs while providing advantageous inductive biases 
                    essential for visual control tasks.

                    While leaving the (a) ViT architecture untouched, 
                    (b) <b>CoIn</b> incorporates two key modules: <u>a CNN encoder</u>, 
                    which captures spatial locality and translation equivariance rich features from the input image, 
                    and a <u>cross attention module</u>, which introduces such biases into the ViT patch token embeddings. 
                    Notably, these enhancements are seamlessly integrated without any modification to the overall ViT architecture.
                </p>
            </div>
        </div>

        <hr>
        <div class="row">
            <div class="col-md-12">
                <h2>
                    <span class="font-weight-normal">Experimental Results</span>
                </h2>
                <br>
                <p class="text-justify">
                    We finetuned various pretrained ViTs with CoIn on 12 control tasks across three domains (Adroit, MetaWorld, DMC).
                    The integration of <b>CoIn</b> with various pretrained ViTs <b>leads to notable performance enhancements 
                    across all pretrained ViT models and their associated control tasks.</b> 
                </p>
            </div>

            <div class="col-md-12">
                <br>
                <p width="50%"  height="auto" style="margin-right:auto;margin-left:auto;text-align:center;">
                    <img src="/CoIn/pictures/table1.png", width="100%">
                </p>
            </div>

            <div class="col-md-12">
                <br>
                <p class="text-justify">
                    In both the <b>(Left)</b> full finetuning and <b>(Right)</b>  Peft finetuning 
                    (freezing the visual encoder and solely finetuning lightweight additional modules) 
                    scenarios against adapters, <b>CoIn consistently outperformed other adapter baselines.</b>

                </p>
            </div>


            <div class="col-md-6">
                <br>
                <p width="50%"  height="auto" style="margin-right:auto;margin-left:auto;text-align:center;">
                    <img src="/CoIn/pictures/table3-1.png", width="100%">
                </p>
            </div>
            
            <div class="col-md-6">
                <br>
                <p width="50%"  height="auto" style="margin-right:auto;margin-left:auto;text-align:center;">
                    <img src="/CoIn/pictures/table3-2.png", width="100%">
                </p>
            </div>

            <div class="col-md-12">
                <br>
                <p class="text-justify">
                    ViT + CoIn demonstrates following improvements: (a) capturing <b>high-frequency</b> signals, 
                    (b) improving <b>translation equivariance,</b> 
                    and (c) enhancing <b>focus on crucial regions for visuo-motor control</b>.
                </p>
            </div>
            <div class="col-md-12">
                <br>
                <div class="col-md-12">
                    <p width="50%"  height="auto" style="margin-right:auto;margin-left:auto;text-align:center;">
                        <img src="/CoIn/pictures/table2.png", width="100%">
                    </p>
                </div>
            </div>

            <div class="row">
                <div class="col-md-12">
                    <hr>
                    <p class="text-justify">
                        The website template was borrowed from <a href="http://mgharbi.com/">Michaël Gharbi</a> and <a href="https://jonbarron.info/">Jon Barron</a>.
                    </p>
                </div>
            </div>



        </div>

    
</body>
</html>