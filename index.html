<!DOCTYPE HTML>
<html lang="en">
<head>
  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-MDPRSPMJ');</script>


  <!-- End Google Tag Manager -->
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- Google tag (gtag.js) -->
  <!--
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-157941252-1"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'UA-157941252-1');
  </script>
  -->
  


  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.1.3/dist/css/bootstrap.min.css" integrity="sha384-MCw98/SFnGE8fJT3GXwEOngsV7Zt27NXFoaoApmYm81iuXoPkFOJwJ8ERdknLPMO" crossorigin="anonymous">
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate"/>
  <meta http-equiv="Pragma" content="no-cache"/>
  <meta http-equiv="Expires" content="0"/>

  <title>Dongyoon Hwang</title>

  <meta name="author" content="Dongyoon Hwang">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="pictures/empty.png">

  <style>
    name {
      display: inline;
    }
  </style>

</head>

<body>
  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-MDPRSPMJ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->
  <div class="container">
    <div class="row" style="margin-top: 30px;">
      <div class="col-sm-6 name-column" style="min-width: 266px;">
        <p style="text-align:center">
          <name>Dongyoon Hwang</name>
        </p>
      </div>
      <div class="col-sm-6 name-column text-right" style="min-width: 266px; margin-top: 10px">
        <p style="text-align:right">
            <a href="https://davian.kaist.ac.kr/"><img src="pictures/davian_logo.png" alt="logo_uni_tue" class="institute-logo-small"></a>
            &nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp&nbsp
            <a href="https://gsai.kaist.ac.kr/?lang=eng/"><img src="pictures/kaistai_logo.png" alt="logo_uni_tue" class="institute-logo-medium"></a>
        </p>
      </div>
    </div>
    <div class="row common-rows">

      <div class="col-xs-12 col-sm-8 personal-column">
        <p> 
          Hi! I am a Ph.D student at KAIST AI in South Korea, advised by <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>. <br> 
        </p>
        <p>
          My current research interest lies in utilizing prior knowledge such as pre-trained models, large-scale trajectory datasets and etc.
          for learning meaningful and diverse behaviors for robotics.
          To do so, I am mainly interested in reinforcement learning, self-supervised learning, and their applications to robotics.
        </p>
        <p>
          Previously, I obtained my B.S at Korea University, 2021. 
          Also, during the winter of 2022, I interned at the Recommendation team at Naver Labs Europe, working closely with 
          Thibaut Thonet and Romain Deffayet. 
          
        </p>

        <p style="text-align:center">
          <a href="mailto:godnpeter@kaist.ac.kr">Email</a> &nbsp/&nbsp
          <a href="">CV</a> &nbsp/&nbsp
          <a href="https://scholar.google.com/citations?hl=ko&user=FQJHN6QAAAAJ=en">Google Scholar</a> &nbsp/&nbsp
          <a href="https://github.com/godnpeter/">Github</a>
        </p>

      </div>
      <div class="col-xs-12 col-sm-4 personal-column" style="margin-top: 30px">
        <img style="width:100%;max-width:100%" alt="profile photo" src="pictures/profile.png" class="hoverZoomLink">
      </div>
    </div>
  </div>

  <div class="container">
    <div class="row section-heading-rows">
      <h4>News</h4>
    </div>
    <div class="row">
      <p>
        <ul>
          <li><b>05.2024.</b> 2 RL papers accepted @ ICML'24: <a href="#icml2024coin">CoIn</a>, and <a href="#icml2024atari-pb">ATARI-PB</a>.
          <li><b>09.2023.</b> 1 RL papers accepted @ NeurIPS'23: <a href="#neurips2023disco-dance">DISCO-DANCE</a>.
        </ul>
      </p>
    </div>
  </div>

  <br>
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Publications</h4>
    </div>
<!-- 
    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
          <img src="pictures/preprint2024dodont.png" alt="preprint2024dodont" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ff9aa2">Skill Discovery</span>
        <br>
        <a href="data/preprint2024dodont.pdf" id="preprint2024dodont">
            <papertitle>
                Do’s and Don’ts:Learning Desirable Skills with Instruction Videos
            </papertitle>
        </a>
        <br>
        <a href="https://mynsng.github.io/">Hyunseung Kim</a>,
        Byungkun Lee,
        <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
        <strong>Dongyoon Hwang</strong>,
        Donghu Kim,
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>,
        <br>
        <em>Preprint</em>.
        <br><br>
        <p style="margin-top: -1%;"> 
            We present DoDont, a skill discovery algorithm that learns diverse behaviors 
            while following the behaviors in "do" videos while avoiding the behaviors in "don't" videos.
        </p>
      </div>
    </div>
     -->
    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/icml2024coin.png" alt="icml2024coin" class="paper-images">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#f1f1b2">Adaptation</span>
        <br>
        <papertitle>
            CoIn: Adapting Pretrained ViTs with Convolution Injector for Visuo-Motor Control
        </papertitle>
        <br>
        <strong>Donyoon Hwang*</strong>, 
        Byungkun Lee*,
        <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
        <a href="https://mynsng.github.io/">Hyunseung Kim</a>,
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        <br>
        <em>ICML'24</em>.
        <br>
        <a href="https://godnpeter.github.io/CoIn/">project page</a>
        <p style="margin-top: -1%;"> 
          We present an add-on convolution module for pre-trained ViT models that injects spatial locality and translation equivariant biases to enhance the adaptability of ViTs for vision-based motor control.
        </p>
    </div>
    </div>


    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/icml2024atari-pb.png" alt="icml2024atari-pb" class="paper-images">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
          <span style="background-color:#e2c7e5">Reinforcement Learning</span>
          <span style="background-color:#ffdac1">Pre-training</span>
          <br>
            <papertitle>
              ATARI-PB: Investigating Pre-Training Objectives for Generalization in Pixel-Based RL
            </papertitle>
          <br>
          Donghu Kim*,
          <a href="https://joonleesky.github.io/">Hojoon Lee*</a>,
          Kyungmin Lee*,
          <strong>Dongyoon Hwang</strong>,
          <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
          <br>
          <em>ICML'24</em>.
          <br><br>
          <p style="margin-top: -1%;"> 
            We investigate which pre-training objectives are beneficial for in-distribution, near-out-of-distribution, and far-out-of-distribution generalization in visual reinforcement learning.
          </p>
        </div>
      </div>

    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/neurips2023disco-dance.png" alt="neurips2023disco-dance" class="paper-images" style="width:90%; margin-left:10%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ff9aa2">Skill Discovery</span>
        <br>
        <a href="https://arxiv.org/abs/2310.20178v2" id="neurips2023disco-dance">
        <papertitle>
            DISCO-DANCE: Learning to Discover Skills through Guidance
        </papertitle>
        </a>
        <br>
        <a href="https://mynsng.github.io/">Hyunseung Kim*</a>, 
        Byungkun Lee*,
        <a href="https://joonleesky.github.io/">Hojoon Lee</a>, 
        <strong>Dongyoon Hwang</strong>,
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        <br>
        <em>NeurIPS'23</em>.
        <br>
        <a href="https://mynsng.github.io/discodance/">project page</a> /
        <a href="https://arxiv.org/abs/2310.20178">arXiv</a> /
        <a href="https://github.com/dojeon-ai/discodance">code</a> /
        <a href="data/neurips2023disco-dance.txt">Bibtex</a>
        <br><br>
        <p style="margin-top: -1%;"> 
        We introduce DISCO-DANCE, a Skill Discovery algorithm focused on learning diverse, task-agnostic behaviors. 
        DISCO-DANCE addresses the common limitation of exploration in skill discovery algorithms through explicit guidance.
        </p>
    </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
    <div class="col-xs-12 custom-col-sm-3 left-column">
        <img src="pictures/icml2023simtpr.png" alt="icml2023simtpr" class="paper-images" style="margin-left:5%; width:98%">
    </div>
    <div class="col-xs-12 col-sm-9 right-column">
        <span style="background-color:#e2c7e5">Reinforcement Learning</span>
        <span style="background-color:#ffdac1">Pre-training</span>
        <br>
        <a href="https://arxiv.org/abs/2306.05637" id="icml2023simtpr">
        <papertitle>
            SimTPR: On the Importance of Feature Decorrelation for Unsupervised Representation Learning for Reinforcement Learning
        </papertitle>
        </a>
        <br>
        <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
        Koanho Lee, 
        <strong>Dongyoon Hwang</strong>, 
        Hyunho Lee, 
        Byungkun Lee, 
        <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
        <br>
        <em>ICML'23</em>.
        <br>
        <a href="https://arxiv.org/abs/2306.05637">arXiv</a> /
        <a href="https://github.com/dojeon-ai/SimTPR">code</a> /
        <a href="https://drive.google.com/file/d/1FPJHtd3uY54P2iOoPBrnt8jD-ud6nF6G/view?usp=sharing">poster</a> /
        <a href="data/icml2023simtpr.txt">Bibtex</a>
        <br><br>
        <p style="margin-top: -1%;"> 
        We present a visual pre-training algorithm grounded in self-predictive learning principles tailored for reinforcement learning.
        </p>
    </div>
    </div>


    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/sigir2022irs.png" alt="sigir2022irs" class="paper-images" style="margin-left:5%">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <span style="background-color:#C9D3D8">Data Mining</span>
            <span style="background-color:#e2c7e5">Reinforcement Learning</span>
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3531869" id="sigir2022irs">
            <papertitle>
                Towards Validating Long-Term User Feedbacks in Interactive Recommender System
            </papertitle>
            </a>
            <br>
            <a href="https://joonleesky.github.io/">Hojoon Lee</a>,
            <strong>Dongyoon Hwang</strong>,
            Kyushik Min,
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
            <br>
            <em>SIGIR'22 (short), <b>Best Honorable Mention Award</b></em>.
            <br>
            <a href="https://dl.acm.org/doi/abs/10.1145/3477495.3531869">arXiv</a> /
            <a href="https://drive.google.com/file/d/13PEGDMrfZaG-PcCp0tx-A_L_2E1MKqQm/view?usp=sharing">poster</a> /
            <a href="data/sigir2022irs.txt">Bibtex</a>
            <br><br>
            <p style="margin-top: -1%;">              
                Through validating the long-term impact of user feedback in MovieLens and Amazon Review datasets, 
                we've discovered that these datasets are inadequate for evaluating reinforcement learning-based interactive recommender systems.        
            </p>
        </div>
    </div>

    <div class="row common-rows" style="margin-top: 3%">
        <div class="col-xs-12 custom-col-sm-3 left-column">
            <img src="pictures/www2022draftrec.png" alt="www2022draftrec" class="paper-images" style="margin-left:8%; width:95%">
        </div>
        <div class="col-xs-12 col-sm-9 right-column">
            <span style="background-color:#C9D3D8">Data Mining</span>
            <span style="background-color:#e2c7e5">Reinforcement Learning</span>
            <span style="background-color:#c9d2fe">Game</span>
            <br>
            <a href="https://dl.acm.org/doi/10.1145/3485447.3512278" id="www2022draftrec">
            <papertitle>
                DraftRec: Personalized Draft Recommendation for Winning in MOBA Games
            </papertitle>
            </a>
            <br>
            <a href="https://joonleesky.github.io/">Hojoon Lee*</a>,
            <strong>Dongyoon Hwang*</strong>,
            <a href="https://mynsng.github.io/">Hyunseung Kim</a>,
            Byungkun Lee, 
            <a href="https://sites.google.com/site/jaegulchoo/">Jaegul Choo</a>.
            <br>
            <em>WWW'22</em>.
            <br>
            <a href="https://arxiv.org/abs/2204.12750">arXiv</a> /
            <a href="https://github.com/dojeon-ai/DraftRec">code</a> /
            <a href="https://drive.google.com/file/d/15L2ZqVutI3xjwJXq9NGbizSZbNsQEXOK/view?usp=sharing">poster</a> /
            <a href="data/www2022draftrec.txt">Bibtex</a>
            <br><br>
            <p style="margin-top: -1%;">                         
                We gathered data from 280,000 matches played by the top 0.3% rank players in Korea for League of Legends. 
                From this, we developed DraftRec, a personalized champion recommendation system aimed at maximizing players' win rates.   
            </p>
        </div>
    </div>

  
  <br>
  <!--
  <div class="container">
    <div class="row section-heading-rows">
      <h4>Other activities</h4>
    </div>
    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/review.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Reviewing activities
        </papertitle>
        <br>
        <ul>
          <li>Serving as a reviewer for NeurIPS'23, ICML'24, ICLR'24.</li>
        </ul>
      </div>
    </div>-->

    <div class="row common-rows">
      <div class="col-xs-12 col-sm-3 left-column">
        <img src="pictures/award.png" class="paper-images">
      </div>
      <div class="col-xs-12 col-sm-9 right-column">
        <papertitle>Awards
        </papertitle>
        <br>
        <ul>
          <li>SIGIR Best Short Paper Honorable Mention, 2022.</li>
          <li>Silver Prize ($2,000 as awards), Korea University Graduation Project, 2021.</li>
        </ul>
      </div>
    </div>
    <br>


  <div class="container">
    <div class="row">
      <div class="col">
        <p style="text-align:right;font-size:small;">
          Template based on <a href="https://jonbarron.info/">Jon Barron's website</a>.
        </p>
      </div>
    </div>
  </div>
</body>

</html>
